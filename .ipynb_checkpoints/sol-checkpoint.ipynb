{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root = 'data'\n",
    "file_train =  os.path.join(root, 'train.csv')\n",
    "file_test = os.path.join(root, 'test.csv')\n",
    "file_result = os.path.join(root, 'submission.csv')\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "n_epochs = 5\n",
    "\n",
    "train_coverage = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f953f4128f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig( level=logging.INFO,)\n",
    "\n",
    "# console_logging_handler = logging.StreamHandler()\n",
    "# console_logging_handler.setLevel(logging.DEBUG)\n",
    "# logging.getLogger('').addHandler(console)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np.random.seed(137)\n",
    "torch.manual_seed(137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_train = pd.read_csv(file_train, encoding = \"UTF-8\")\n",
    "pd_test = pd.read_csv(file_test, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class drds(Dataset):\n",
    "    def __init__(self, data, train=True):\n",
    "        self.data = data\n",
    "        self.train = train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        cdata = self.data.iloc[index]\n",
    "        if self.train:\n",
    "            inputs = torch.FloatTensor(cdata[1:]).view(1,28,28)\n",
    "            target = torch.LongTensor([cdata[0]])[0]\n",
    "        else:\n",
    "            inputs = torch.FloatTensor(cdata).view(1,28,28)\n",
    "            target = torch.LongTensor([0])[0]\n",
    "        return inputs, target\n",
    "\n",
    "ds_train = drds(pd_train, train=True)\n",
    "ds_test = drds(pd_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def get_sampler(start, stop):\n",
    "    return SubsetRandomSampler(np.arange(start, stop, dtype=np.int64))\n",
    "\n",
    "cnt_train = math.ceil(train_coverage * ds_train.__len__())\n",
    "\n",
    "loader_train = DataLoader( ds_train, batch_size=batch_size, shuffle=False,\n",
    "            sampler=get_sampler(0, cnt_train), num_workers=0, drop_last=True, )\n",
    "\n",
    "loader_val = DataLoader( ds_train, batch_size=batch_size, shuffle=False,\n",
    "            sampler=get_sampler(0, cnt_train), num_workers=0, drop_last=True, )\n",
    "\n",
    "loader_test = DataLoader( ds_test, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(\"using device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initialized cnn.conv, num feature dimension: 400\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "p_dropout = 0.001\n",
    "\n",
    "class drnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(drnet, self).__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=8,\n",
    "                kernel_size=2,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=8,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # More layers\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=p_dropout),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # \n",
    "            nn.BatchNorm2d(16), # BN\n",
    "            nn.ReLU(inplace=True), # ReLU\n",
    "        )\n",
    "\n",
    "        in_features = int(self.conv(torch.zeros(1, 1, 28,28)).size(1))\n",
    "        out_features = 10\n",
    "        \n",
    "        logging.info(\"initialized cnn.conv, num feature dimension: {}\".format(\n",
    "            in_features))\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            # nn.LogSoftmax(dim=1),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        self.models = {}\n",
    "\n",
    "    def conv(self, x):\n",
    "        x = self.seq(x)\n",
    "        # x = torch.mean(x, dim=2, keepdim=True)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print('#### view:shape: ', x.shape)\n",
    "        # view:shape:  torch.Size([2880, 14976])\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def save(self, key):\n",
    "        model = self.state_dict()\n",
    "        self.models[key] = model\n",
    "\n",
    "    def load(self, key):\n",
    "        if key in self.models:\n",
    "            self.load_state_dict(self.models[key], strict=True)\n",
    "        else:\n",
    "            logging.error(\"key {} not found\".format(key))\n",
    "\n",
    "net = drnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "# batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 0, progress: 19.85% loss: 1.4628/1.4628\n",
      "epoch: 0, progress: 39.69% loss: 1.4631/1.4630\n",
      "epoch: 0, progress: 59.54% loss: 1.4631/1.4630\n",
      "epoch: 0, progress: 79.39% loss: 1.4640/1.4633\n",
      "epoch: 0, progress: 99.24% loss: 1.4637/1.4633\n",
      "validation: 0, progress: 19.85% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 0, progress: 39.69% loss: 1.4635/1.4636, acc: 0.9976\n",
      "validation: 0, progress: 59.54% loss: 1.4616/1.4629, acc: 0.9982\n",
      "validation: 0, progress: 79.39% loss: 1.4640/1.4632, acc: 0.9980\n",
      "validation: 0, progress: 99.24% loss: 1.4641/1.4634, acc: 0.9978\n",
      "epoch: 0, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 1\n",
      "epoch: 1, progress: 19.85% loss: 1.4631/1.4631\n",
      "epoch: 1, progress: 39.69% loss: 1.4646/1.4639\n",
      "epoch: 1, progress: 59.54% loss: 1.4637/1.4638\n",
      "epoch: 1, progress: 79.39% loss: 1.4625/1.4635\n",
      "epoch: 1, progress: 99.24% loss: 1.4629/1.4634\n",
      "validation: 1, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 1, progress: 39.69% loss: 1.4641/1.4637, acc: 0.9974\n",
      "validation: 1, progress: 59.54% loss: 1.4634/1.4636, acc: 0.9975\n",
      "validation: 1, progress: 79.39% loss: 1.4627/1.4634, acc: 0.9978\n",
      "validation: 1, progress: 99.24% loss: 1.4631/1.4633, acc: 0.9978\n",
      "epoch: 1, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 2\n",
      "epoch: 2, progress: 19.85% loss: 1.4627/1.4627\n",
      "epoch: 2, progress: 39.69% loss: 1.4625/1.4626\n",
      "epoch: 2, progress: 59.54% loss: 1.4640/1.4631\n",
      "epoch: 2, progress: 79.39% loss: 1.4644/1.4634\n",
      "epoch: 2, progress: 99.24% loss: 1.4631/1.4633\n",
      "validation: 2, progress: 19.85% loss: 1.4628/1.4628, acc: 0.9983\n",
      "validation: 2, progress: 39.69% loss: 1.4635/1.4632, acc: 0.9980\n",
      "validation: 2, progress: 59.54% loss: 1.4633/1.4632, acc: 0.9979\n",
      "validation: 2, progress: 79.39% loss: 1.4633/1.4632, acc: 0.9979\n",
      "validation: 2, progress: 99.24% loss: 1.4641/1.4634, acc: 0.9978\n",
      "epoch: 2, train loss: 1.4633, validation accuracy: 0.9978\n",
      "epoch: 3\n",
      "epoch: 3, progress: 19.85% loss: 1.4631/1.4631\n",
      "epoch: 3, progress: 39.69% loss: 1.4636/1.4633\n",
      "epoch: 3, progress: 59.54% loss: 1.4642/1.4636\n",
      "epoch: 3, progress: 79.39% loss: 1.4628/1.4634\n",
      "epoch: 3, progress: 99.24% loss: 1.4633/1.4634\n",
      "validation: 3, progress: 19.85% loss: 1.4640/1.4640, acc: 0.9971\n",
      "validation: 3, progress: 39.69% loss: 1.4640/1.4640, acc: 0.9971\n",
      "validation: 3, progress: 59.54% loss: 1.4634/1.4638, acc: 0.9973\n",
      "validation: 3, progress: 79.39% loss: 1.4625/1.4635, acc: 0.9977\n",
      "validation: 3, progress: 99.24% loss: 1.4627/1.4633, acc: 0.9978\n",
      "epoch: 3, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 4\n",
      "epoch: 4, progress: 19.85% loss: 1.4636/1.4636\n",
      "epoch: 4, progress: 39.69% loss: 1.4632/1.4634\n",
      "epoch: 4, progress: 59.54% loss: 1.4625/1.4631\n",
      "epoch: 4, progress: 79.39% loss: 1.4636/1.4632\n",
      "epoch: 4, progress: 99.24% loss: 1.4640/1.4634\n",
      "validation: 4, progress: 19.85% loss: 1.4630/1.4630, acc: 0.9982\n",
      "validation: 4, progress: 39.69% loss: 1.4635/1.4633, acc: 0.9979\n",
      "validation: 4, progress: 59.54% loss: 1.4645/1.4637, acc: 0.9975\n",
      "validation: 4, progress: 79.39% loss: 1.4622/1.4633, acc: 0.9979\n",
      "validation: 4, progress: 99.24% loss: 1.4634/1.4633, acc: 0.9978\n",
      "epoch: 4, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 5\n",
      "epoch: 5, progress: 19.85% loss: 1.4633/1.4633\n",
      "epoch: 5, progress: 39.69% loss: 1.4628/1.4630\n",
      "epoch: 5, progress: 59.54% loss: 1.4624/1.4628\n",
      "epoch: 5, progress: 79.39% loss: 1.4643/1.4632\n",
      "epoch: 5, progress: 99.24% loss: 1.4642/1.4634\n",
      "validation: 5, progress: 19.85% loss: 1.4620/1.4620, acc: 0.9991\n",
      "validation: 5, progress: 39.69% loss: 1.4633/1.4627, acc: 0.9985\n",
      "validation: 5, progress: 59.54% loss: 1.4630/1.4628, acc: 0.9984\n",
      "validation: 5, progress: 79.39% loss: 1.4652/1.4634, acc: 0.9978\n",
      "validation: 5, progress: 99.24% loss: 1.4632/1.4633, acc: 0.9978\n",
      "epoch: 5, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 6\n",
      "epoch: 6, progress: 19.85% loss: 1.4634/1.4634\n",
      "epoch: 6, progress: 39.69% loss: 1.4637/1.4636\n",
      "epoch: 6, progress: 59.54% loss: 1.4623/1.4632\n",
      "epoch: 6, progress: 79.39% loss: 1.4641/1.4634\n",
      "epoch: 6, progress: 99.24% loss: 1.4628/1.4633\n",
      "validation: 6, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 6, progress: 39.69% loss: 1.4639/1.4636, acc: 0.9976\n",
      "validation: 6, progress: 59.54% loss: 1.4635/1.4636, acc: 0.9976\n",
      "validation: 6, progress: 79.39% loss: 1.4634/1.4635, acc: 0.9976\n",
      "validation: 6, progress: 99.24% loss: 1.4628/1.4634, acc: 0.9978\n",
      "epoch: 6, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 7\n",
      "epoch: 7, progress: 19.85% loss: 1.4637/1.4637\n",
      "epoch: 7, progress: 39.69% loss: 1.4637/1.4637\n",
      "epoch: 7, progress: 59.54% loss: 1.4625/1.4633\n",
      "epoch: 7, progress: 79.39% loss: 1.4629/1.4632\n",
      "epoch: 7, progress: 99.24% loss: 1.4640/1.4634\n",
      "validation: 7, progress: 19.85% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 7, progress: 39.69% loss: 1.4631/1.4633, acc: 0.9978\n",
      "validation: 7, progress: 59.54% loss: 1.4633/1.4633, acc: 0.9978\n",
      "validation: 7, progress: 79.39% loss: 1.4636/1.4634, acc: 0.9978\n",
      "validation: 7, progress: 99.24% loss: 1.4634/1.4634, acc: 0.9978\n",
      "epoch: 7, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 8\n",
      "epoch: 8, progress: 19.85% loss: 1.4639/1.4639\n",
      "epoch: 8, progress: 39.69% loss: 1.4631/1.4635\n",
      "epoch: 8, progress: 59.54% loss: 1.4639/1.4636\n",
      "epoch: 8, progress: 79.39% loss: 1.4629/1.4634\n",
      "epoch: 8, progress: 99.24% loss: 1.4629/1.4633\n",
      "validation: 8, progress: 19.85% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 8, progress: 39.69% loss: 1.4640/1.4638, acc: 0.9974\n",
      "validation: 8, progress: 59.54% loss: 1.4634/1.4637, acc: 0.9975\n",
      "validation: 8, progress: 79.39% loss: 1.4634/1.4636, acc: 0.9976\n",
      "validation: 8, progress: 99.24% loss: 1.4625/1.4634, acc: 0.9978\n",
      "epoch: 8, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 9\n",
      "epoch: 9, progress: 19.85% loss: 1.4631/1.4631\n",
      "epoch: 9, progress: 39.69% loss: 1.4631/1.4631\n",
      "epoch: 9, progress: 59.54% loss: 1.4628/1.4630\n",
      "epoch: 9, progress: 79.39% loss: 1.4637/1.4632\n",
      "epoch: 9, progress: 99.24% loss: 1.4640/1.4633\n",
      "validation: 9, progress: 19.85% loss: 1.4632/1.4632, acc: 0.9979\n",
      "validation: 9, progress: 39.69% loss: 1.4631/1.4632, acc: 0.9980\n",
      "validation: 9, progress: 59.54% loss: 1.4634/1.4633, acc: 0.9979\n",
      "validation: 9, progress: 79.39% loss: 1.4630/1.4632, acc: 0.9980\n",
      "validation: 9, progress: 99.24% loss: 1.4640/1.4633, acc: 0.9978\n",
      "epoch: 9, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 10\n",
      "epoch: 10, progress: 19.85% loss: 1.4627/1.4627\n",
      "epoch: 10, progress: 39.69% loss: 1.4630/1.4628\n",
      "epoch: 10, progress: 59.54% loss: 1.4640/1.4632\n",
      "epoch: 10, progress: 79.39% loss: 1.4632/1.4632\n",
      "epoch: 10, progress: 99.24% loss: 1.4640/1.4634\n",
      "validation: 10, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 10, progress: 39.69% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 10, progress: 59.54% loss: 1.4628/1.4631, acc: 0.9980\n",
      "validation: 10, progress: 79.39% loss: 1.4637/1.4633, acc: 0.9979\n",
      "validation: 10, progress: 99.24% loss: 1.4636/1.4633, acc: 0.9978\n",
      "epoch: 10, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 11\n",
      "epoch: 11, progress: 19.85% loss: 1.4637/1.4637\n",
      "epoch: 11, progress: 39.69% loss: 1.4631/1.4634\n",
      "epoch: 11, progress: 59.54% loss: 1.4636/1.4634\n",
      "epoch: 11, progress: 79.39% loss: 1.4628/1.4633\n",
      "epoch: 11, progress: 99.24% loss: 1.4634/1.4633\n",
      "validation: 11, progress: 19.85% loss: 1.4640/1.4640, acc: 0.9971\n",
      "validation: 11, progress: 39.69% loss: 1.4636/1.4638, acc: 0.9974\n",
      "validation: 11, progress: 59.54% loss: 1.4629/1.4635, acc: 0.9976\n",
      "validation: 11, progress: 79.39% loss: 1.4631/1.4634, acc: 0.9977\n",
      "validation: 11, progress: 99.24% loss: 1.4633/1.4634, acc: 0.9978\n",
      "epoch: 11, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 12\n",
      "epoch: 12, progress: 19.85% loss: 1.4639/1.4639\n",
      "epoch: 12, progress: 39.69% loss: 1.4636/1.4637\n",
      "epoch: 12, progress: 59.54% loss: 1.4630/1.4635\n",
      "epoch: 12, progress: 79.39% loss: 1.4640/1.4636\n",
      "epoch: 12, progress: 99.24% loss: 1.4623/1.4633\n",
      "validation: 12, progress: 19.85% loss: 1.4635/1.4635, acc: 0.9977\n",
      "validation: 12, progress: 39.69% loss: 1.4628/1.4631, acc: 0.9980\n",
      "validation: 12, progress: 59.54% loss: 1.4636/1.4633, acc: 0.9979\n",
      "validation: 12, progress: 79.39% loss: 1.4638/1.4634, acc: 0.9977\n",
      "validation: 12, progress: 99.24% loss: 1.4629/1.4633, acc: 0.9978\n",
      "epoch: 12, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, progress: 19.85% loss: 1.4631/1.4631\n",
      "epoch: 13, progress: 39.69% loss: 1.4642/1.4636\n",
      "epoch: 13, progress: 59.54% loss: 1.4631/1.4634\n",
      "epoch: 13, progress: 79.39% loss: 1.4626/1.4632\n",
      "epoch: 13, progress: 99.24% loss: 1.4639/1.4634\n",
      "validation: 13, progress: 19.85% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 13, progress: 39.69% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 13, progress: 59.54% loss: 1.4631/1.4634, acc: 0.9977\n",
      "validation: 13, progress: 79.39% loss: 1.4635/1.4634, acc: 0.9977\n",
      "validation: 13, progress: 99.24% loss: 1.4631/1.4634, acc: 0.9978\n",
      "epoch: 13, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 14\n",
      "epoch: 14, progress: 19.85% loss: 1.4623/1.4623\n",
      "epoch: 14, progress: 39.69% loss: 1.4638/1.4631\n",
      "epoch: 14, progress: 59.54% loss: 1.4636/1.4633\n",
      "epoch: 14, progress: 79.39% loss: 1.4634/1.4633\n",
      "epoch: 14, progress: 99.24% loss: 1.4635/1.4633\n",
      "validation: 14, progress: 19.85% loss: 1.4624/1.4624, acc: 0.9988\n",
      "validation: 14, progress: 39.69% loss: 1.4633/1.4628, acc: 0.9983\n",
      "validation: 14, progress: 59.54% loss: 1.4635/1.4631, acc: 0.9981\n",
      "validation: 14, progress: 79.39% loss: 1.4639/1.4633, acc: 0.9979\n",
      "validation: 14, progress: 99.24% loss: 1.4637/1.4633, acc: 0.9978\n",
      "epoch: 14, train loss: 1.4633, validation accuracy: 0.9978\n",
      "epoch: 15\n",
      "epoch: 15, progress: 19.85% loss: 1.4642/1.4642\n",
      "epoch: 15, progress: 39.69% loss: 1.4629/1.4636\n",
      "epoch: 15, progress: 59.54% loss: 1.4633/1.4635\n",
      "epoch: 15, progress: 79.39% loss: 1.4629/1.4633\n",
      "epoch: 15, progress: 99.24% loss: 1.4636/1.4634\n",
      "validation: 15, progress: 19.85% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 15, progress: 39.69% loss: 1.4635/1.4633, acc: 0.9978\n",
      "validation: 15, progress: 59.54% loss: 1.4639/1.4635, acc: 0.9976\n",
      "validation: 15, progress: 79.39% loss: 1.4631/1.4634, acc: 0.9977\n",
      "validation: 15, progress: 99.24% loss: 1.4630/1.4633, acc: 0.9978\n",
      "epoch: 15, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 16\n",
      "epoch: 16, progress: 19.85% loss: 1.4637/1.4637\n",
      "epoch: 16, progress: 39.69% loss: 1.4636/1.4636\n",
      "epoch: 16, progress: 59.54% loss: 1.4634/1.4636\n",
      "epoch: 16, progress: 79.39% loss: 1.4630/1.4634\n",
      "epoch: 16, progress: 99.24% loss: 1.4633/1.4634\n",
      "validation: 16, progress: 19.85% loss: 1.4637/1.4637, acc: 0.9974\n",
      "validation: 16, progress: 39.69% loss: 1.4628/1.4633, acc: 0.9979\n",
      "validation: 16, progress: 59.54% loss: 1.4634/1.4633, acc: 0.9978\n",
      "validation: 16, progress: 79.39% loss: 1.4640/1.4635, acc: 0.9977\n",
      "validation: 16, progress: 99.24% loss: 1.4628/1.4633, acc: 0.9978\n",
      "epoch: 16, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 17\n",
      "epoch: 17, progress: 19.85% loss: 1.4634/1.4634\n",
      "epoch: 17, progress: 39.69% loss: 1.4627/1.4630\n",
      "epoch: 17, progress: 59.54% loss: 1.4631/1.4631\n",
      "epoch: 17, progress: 79.39% loss: 1.4631/1.4631\n",
      "epoch: 17, progress: 99.24% loss: 1.4646/1.4634\n",
      "validation: 17, progress: 19.85% loss: 1.4634/1.4634, acc: 0.9977\n",
      "validation: 17, progress: 39.69% loss: 1.4638/1.4636, acc: 0.9975\n",
      "validation: 17, progress: 59.54% loss: 1.4635/1.4636, acc: 0.9975\n",
      "validation: 17, progress: 79.39% loss: 1.4631/1.4635, acc: 0.9977\n",
      "validation: 17, progress: 99.24% loss: 1.4627/1.4633, acc: 0.9978\n",
      "epoch: 17, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 18\n",
      "epoch: 18, progress: 19.85% loss: 1.4628/1.4628\n",
      "epoch: 18, progress: 39.69% loss: 1.4628/1.4628\n",
      "epoch: 18, progress: 59.54% loss: 1.4638/1.4632\n",
      "epoch: 18, progress: 79.39% loss: 1.4640/1.4634\n",
      "epoch: 18, progress: 99.24% loss: 1.4634/1.4634\n",
      "validation: 18, progress: 19.85% loss: 1.4638/1.4638, acc: 0.9973\n",
      "validation: 18, progress: 39.69% loss: 1.4637/1.4638, acc: 0.9974\n",
      "validation: 18, progress: 59.54% loss: 1.4634/1.4637, acc: 0.9975\n",
      "validation: 18, progress: 79.39% loss: 1.4631/1.4635, acc: 0.9976\n",
      "validation: 18, progress: 99.24% loss: 1.4628/1.4634, acc: 0.9978\n",
      "epoch: 18, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 19\n",
      "epoch: 19, progress: 19.85% loss: 1.4625/1.4625\n",
      "epoch: 19, progress: 39.69% loss: 1.4635/1.4630\n",
      "epoch: 19, progress: 59.54% loss: 1.4631/1.4630\n",
      "epoch: 19, progress: 79.39% loss: 1.4637/1.4632\n",
      "epoch: 19, progress: 99.24% loss: 1.4634/1.4632\n",
      "validation: 19, progress: 19.85% loss: 1.4638/1.4638, acc: 0.9973\n",
      "validation: 19, progress: 39.69% loss: 1.4643/1.4641, acc: 0.9971\n",
      "validation: 19, progress: 59.54% loss: 1.4630/1.4637, acc: 0.9974\n",
      "validation: 19, progress: 79.39% loss: 1.4625/1.4634, acc: 0.9977\n",
      "validation: 19, progress: 99.24% loss: 1.4631/1.4633, acc: 0.9978\n",
      "epoch: 19, train loss: 1.4633, validation accuracy: 0.9978\n",
      "epoch: 20\n",
      "epoch: 20, progress: 19.85% loss: 1.4632/1.4632\n",
      "epoch: 20, progress: 39.69% loss: 1.4633/1.4633\n",
      "epoch: 20, progress: 59.54% loss: 1.4634/1.4633\n",
      "epoch: 20, progress: 79.39% loss: 1.4637/1.4634\n",
      "epoch: 20, progress: 99.24% loss: 1.4632/1.4634\n",
      "validation: 20, progress: 19.85% loss: 1.4624/1.4624, acc: 0.9988\n",
      "validation: 20, progress: 39.69% loss: 1.4640/1.4632, acc: 0.9980\n",
      "validation: 20, progress: 59.54% loss: 1.4634/1.4633, acc: 0.9979\n",
      "validation: 20, progress: 79.39% loss: 1.4638/1.4634, acc: 0.9977\n",
      "validation: 20, progress: 99.24% loss: 1.4633/1.4634, acc: 0.9978\n",
      "epoch: 20, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 21\n",
      "epoch: 21, progress: 19.85% loss: 1.4631/1.4631\n",
      "epoch: 21, progress: 39.69% loss: 1.4636/1.4633\n",
      "epoch: 21, progress: 59.54% loss: 1.4629/1.4632\n",
      "epoch: 21, progress: 79.39% loss: 1.4638/1.4634\n",
      "epoch: 21, progress: 99.24% loss: 1.4633/1.4633\n",
      "validation: 21, progress: 19.85% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 21, progress: 39.69% loss: 1.4634/1.4633, acc: 0.9979\n",
      "validation: 21, progress: 59.54% loss: 1.4643/1.4636, acc: 0.9975\n",
      "validation: 21, progress: 79.39% loss: 1.4631/1.4635, acc: 0.9977\n",
      "validation: 21, progress: 99.24% loss: 1.4630/1.4634, acc: 0.9978\n",
      "epoch: 21, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 22\n",
      "epoch: 22, progress: 19.85% loss: 1.4638/1.4638\n",
      "epoch: 22, progress: 39.69% loss: 1.4630/1.4634\n",
      "epoch: 22, progress: 59.54% loss: 1.4634/1.4634\n",
      "epoch: 22, progress: 79.39% loss: 1.4637/1.4635\n",
      "epoch: 22, progress: 99.24% loss: 1.4631/1.4634\n",
      "validation: 22, progress: 19.85% loss: 1.4635/1.4635, acc: 0.9976\n",
      "validation: 22, progress: 39.69% loss: 1.4634/1.4635, acc: 0.9977\n",
      "validation: 22, progress: 59.54% loss: 1.4633/1.4634, acc: 0.9977\n",
      "validation: 22, progress: 79.39% loss: 1.4626/1.4632, acc: 0.9979\n",
      "validation: 22, progress: 99.24% loss: 1.4640/1.4634, acc: 0.9978\n",
      "epoch: 22, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 23\n",
      "epoch: 23, progress: 19.85% loss: 1.4628/1.4628\n",
      "epoch: 23, progress: 39.69% loss: 1.4633/1.4630\n",
      "epoch: 23, progress: 59.54% loss: 1.4636/1.4632\n",
      "epoch: 23, progress: 79.39% loss: 1.4631/1.4632\n",
      "epoch: 23, progress: 99.24% loss: 1.4638/1.4633\n",
      "validation: 23, progress: 19.85% loss: 1.4624/1.4624, acc: 0.9988\n",
      "validation: 23, progress: 39.69% loss: 1.4643/1.4633, acc: 0.9978\n",
      "validation: 23, progress: 59.54% loss: 1.4634/1.4634, acc: 0.9978\n",
      "validation: 23, progress: 79.39% loss: 1.4633/1.4633, acc: 0.9978\n",
      "validation: 23, progress: 99.24% loss: 1.4632/1.4633, acc: 0.9978\n",
      "epoch: 23, train loss: 1.4633, validation accuracy: 0.9978\n",
      "epoch: 24\n",
      "epoch: 24, progress: 19.85% loss: 1.4636/1.4636\n",
      "epoch: 24, progress: 39.69% loss: 1.4626/1.4631\n",
      "epoch: 24, progress: 59.54% loss: 1.4639/1.4634\n",
      "epoch: 24, progress: 79.39% loss: 1.4630/1.4633\n",
      "epoch: 24, progress: 99.24% loss: 1.4637/1.4633\n",
      "validation: 24, progress: 19.85% loss: 1.4640/1.4640, acc: 0.9971\n",
      "validation: 24, progress: 39.69% loss: 1.4641/1.4641, acc: 0.9971\n",
      "validation: 24, progress: 59.54% loss: 1.4625/1.4635, acc: 0.9976\n",
      "validation: 24, progress: 79.39% loss: 1.4633/1.4635, acc: 0.9977\n",
      "validation: 24, progress: 99.24% loss: 1.4630/1.4634, acc: 0.9978\n",
      "epoch: 24, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 25\n",
      "epoch: 25, progress: 19.85% loss: 1.4642/1.4642\n",
      "epoch: 25, progress: 39.69% loss: 1.4640/1.4641\n",
      "epoch: 25, progress: 59.54% loss: 1.4628/1.4637\n",
      "epoch: 25, progress: 79.39% loss: 1.4629/1.4635\n",
      "epoch: 25, progress: 99.24% loss: 1.4630/1.4634\n",
      "validation: 25, progress: 19.85% loss: 1.4628/1.4628, acc: 0.9983\n",
      "validation: 25, progress: 39.69% loss: 1.4638/1.4633, acc: 0.9978\n",
      "validation: 25, progress: 59.54% loss: 1.4630/1.4632, acc: 0.9979\n",
      "validation: 25, progress: 79.39% loss: 1.4636/1.4633, acc: 0.9979\n",
      "validation: 25, progress: 99.24% loss: 1.4634/1.4633, acc: 0.9978\n",
      "epoch: 25, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, progress: 19.85% loss: 1.4634/1.4634\n",
      "epoch: 26, progress: 39.69% loss: 1.4637/1.4635\n",
      "epoch: 26, progress: 59.54% loss: 1.4637/1.4636\n",
      "epoch: 26, progress: 79.39% loss: 1.4625/1.4633\n",
      "epoch: 26, progress: 99.24% loss: 1.4630/1.4633\n",
      "validation: 26, progress: 19.85% loss: 1.4639/1.4639, acc: 0.9973\n",
      "validation: 26, progress: 39.69% loss: 1.4637/1.4638, acc: 0.9974\n",
      "validation: 26, progress: 59.54% loss: 1.4628/1.4635, acc: 0.9977\n",
      "validation: 26, progress: 79.39% loss: 1.4630/1.4633, acc: 0.9978\n",
      "validation: 26, progress: 99.24% loss: 1.4636/1.4634, acc: 0.9978\n",
      "epoch: 26, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 27\n",
      "epoch: 27, progress: 19.85% loss: 1.4640/1.4640\n",
      "epoch: 27, progress: 39.69% loss: 1.4637/1.4639\n",
      "epoch: 27, progress: 59.54% loss: 1.4632/1.4637\n",
      "epoch: 27, progress: 79.39% loss: 1.4628/1.4634\n",
      "epoch: 27, progress: 99.24% loss: 1.4630/1.4633\n",
      "validation: 27, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 27, progress: 39.69% loss: 1.4634/1.4633, acc: 0.9978\n",
      "validation: 27, progress: 59.54% loss: 1.4628/1.4632, acc: 0.9980\n",
      "validation: 27, progress: 79.39% loss: 1.4636/1.4633, acc: 0.9979\n",
      "validation: 27, progress: 99.24% loss: 1.4637/1.4633, acc: 0.9978\n",
      "epoch: 27, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 28\n",
      "epoch: 28, progress: 19.85% loss: 1.4631/1.4631\n",
      "epoch: 28, progress: 39.69% loss: 1.4629/1.4630\n",
      "epoch: 28, progress: 59.54% loss: 1.4635/1.4632\n",
      "epoch: 28, progress: 79.39% loss: 1.4640/1.4634\n",
      "epoch: 28, progress: 99.24% loss: 1.4631/1.4633\n",
      "validation: 28, progress: 19.85% loss: 1.4634/1.4634, acc: 0.9977\n",
      "validation: 28, progress: 39.69% loss: 1.4638/1.4636, acc: 0.9975\n",
      "validation: 28, progress: 59.54% loss: 1.4633/1.4635, acc: 0.9976\n",
      "validation: 28, progress: 79.39% loss: 1.4636/1.4635, acc: 0.9976\n",
      "validation: 28, progress: 99.24% loss: 1.4628/1.4634, acc: 0.9978\n",
      "epoch: 28, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 29\n",
      "epoch: 29, progress: 19.85% loss: 1.4640/1.4640\n",
      "epoch: 29, progress: 39.69% loss: 1.4633/1.4636\n",
      "epoch: 29, progress: 59.54% loss: 1.4634/1.4636\n",
      "epoch: 29, progress: 79.39% loss: 1.4626/1.4633\n",
      "epoch: 29, progress: 99.24% loss: 1.4635/1.4634\n",
      "validation: 29, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 29, progress: 39.69% loss: 1.4631/1.4632, acc: 0.9980\n",
      "validation: 29, progress: 59.54% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 29, progress: 79.39% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 29, progress: 99.24% loss: 1.4642/1.4633, acc: 0.9978\n",
      "epoch: 29, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 30\n",
      "epoch: 30, progress: 19.85% loss: 1.4632/1.4632\n",
      "epoch: 30, progress: 39.69% loss: 1.4637/1.4635\n",
      "epoch: 30, progress: 59.54% loss: 1.4639/1.4636\n",
      "epoch: 30, progress: 79.39% loss: 1.4632/1.4635\n",
      "epoch: 30, progress: 99.24% loss: 1.4628/1.4634\n",
      "validation: 30, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 30, progress: 39.69% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 30, progress: 59.54% loss: 1.4638/1.4635, acc: 0.9977\n",
      "validation: 30, progress: 79.39% loss: 1.4632/1.4634, acc: 0.9977\n",
      "validation: 30, progress: 99.24% loss: 1.4631/1.4633, acc: 0.9978\n",
      "epoch: 30, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 31\n",
      "epoch: 31, progress: 19.85% loss: 1.4639/1.4639\n",
      "epoch: 31, progress: 39.69% loss: 1.4628/1.4633\n",
      "epoch: 31, progress: 59.54% loss: 1.4631/1.4633\n",
      "epoch: 31, progress: 79.39% loss: 1.4631/1.4632\n",
      "epoch: 31, progress: 99.24% loss: 1.4640/1.4634\n",
      "validation: 31, progress: 19.85% loss: 1.4637/1.4637, acc: 0.9974\n",
      "validation: 31, progress: 39.69% loss: 1.4635/1.4636, acc: 0.9975\n",
      "validation: 31, progress: 59.54% loss: 1.4632/1.4635, acc: 0.9976\n",
      "validation: 31, progress: 79.39% loss: 1.4637/1.4635, acc: 0.9976\n",
      "validation: 31, progress: 99.24% loss: 1.4625/1.4633, acc: 0.9978\n",
      "epoch: 31, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 32\n",
      "epoch: 32, progress: 19.85% loss: 1.4637/1.4637\n",
      "epoch: 32, progress: 39.69% loss: 1.4631/1.4634\n",
      "epoch: 32, progress: 59.54% loss: 1.4625/1.4631\n",
      "epoch: 32, progress: 79.39% loss: 1.4637/1.4633\n",
      "epoch: 32, progress: 99.24% loss: 1.4638/1.4634\n",
      "validation: 32, progress: 19.85% loss: 1.4628/1.4628, acc: 0.9983\n",
      "validation: 32, progress: 39.69% loss: 1.4634/1.4631, acc: 0.9980\n",
      "validation: 32, progress: 59.54% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 32, progress: 79.39% loss: 1.4643/1.4634, acc: 0.9977\n",
      "validation: 32, progress: 99.24% loss: 1.4633/1.4634, acc: 0.9978\n",
      "epoch: 32, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 33\n",
      "epoch: 33, progress: 19.85% loss: 1.4639/1.4639\n",
      "epoch: 33, progress: 39.69% loss: 1.4637/1.4638\n",
      "epoch: 33, progress: 59.54% loss: 1.4633/1.4636\n",
      "epoch: 33, progress: 79.39% loss: 1.4632/1.4635\n",
      "epoch: 33, progress: 99.24% loss: 1.4628/1.4634\n",
      "validation: 33, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 33, progress: 39.69% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 33, progress: 59.54% loss: 1.4625/1.4630, acc: 0.9981\n",
      "validation: 33, progress: 79.39% loss: 1.4641/1.4633, acc: 0.9979\n",
      "validation: 33, progress: 99.24% loss: 1.4635/1.4633, acc: 0.9978\n",
      "epoch: 33, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 34\n",
      "epoch: 34, progress: 19.85% loss: 1.4636/1.4636\n",
      "epoch: 34, progress: 39.69% loss: 1.4631/1.4633\n",
      "epoch: 34, progress: 59.54% loss: 1.4634/1.4634\n",
      "epoch: 34, progress: 79.39% loss: 1.4637/1.4634\n",
      "epoch: 34, progress: 99.24% loss: 1.4631/1.4634\n",
      "validation: 34, progress: 19.85% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 34, progress: 39.69% loss: 1.4637/1.4634, acc: 0.9977\n",
      "validation: 34, progress: 59.54% loss: 1.4637/1.4635, acc: 0.9976\n",
      "validation: 34, progress: 79.39% loss: 1.4629/1.4634, acc: 0.9978\n",
      "validation: 34, progress: 99.24% loss: 1.4633/1.4633, acc: 0.9978\n",
      "epoch: 34, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 35\n",
      "epoch: 35, progress: 19.85% loss: 1.4628/1.4628\n",
      "epoch: 35, progress: 39.69% loss: 1.4637/1.4633\n",
      "epoch: 35, progress: 59.54% loss: 1.4631/1.4632\n",
      "epoch: 35, progress: 79.39% loss: 1.4640/1.4634\n",
      "epoch: 35, progress: 99.24% loss: 1.4632/1.4634\n",
      "validation: 35, progress: 19.85% loss: 1.4629/1.4629, acc: 0.9982\n",
      "validation: 35, progress: 39.69% loss: 1.4637/1.4633, acc: 0.9978\n",
      "validation: 35, progress: 59.54% loss: 1.4634/1.4633, acc: 0.9978\n",
      "validation: 35, progress: 79.39% loss: 1.4633/1.4633, acc: 0.9978\n",
      "validation: 35, progress: 99.24% loss: 1.4636/1.4634, acc: 0.9978\n",
      "epoch: 35, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 36\n",
      "epoch: 36, progress: 19.85% loss: 1.4623/1.4623\n",
      "epoch: 36, progress: 39.69% loss: 1.4639/1.4631\n",
      "epoch: 36, progress: 59.54% loss: 1.4626/1.4629\n",
      "epoch: 36, progress: 79.39% loss: 1.4640/1.4632\n",
      "epoch: 36, progress: 99.24% loss: 1.4639/1.4633\n",
      "validation: 36, progress: 19.85% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 36, progress: 39.69% loss: 1.4630/1.4630, acc: 0.9981\n",
      "validation: 36, progress: 59.54% loss: 1.4635/1.4632, acc: 0.9979\n",
      "validation: 36, progress: 79.39% loss: 1.4634/1.4633, acc: 0.9979\n",
      "validation: 36, progress: 99.24% loss: 1.4637/1.4633, acc: 0.9978\n",
      "epoch: 36, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 37\n",
      "epoch: 37, progress: 19.85% loss: 1.4634/1.4634\n",
      "epoch: 37, progress: 39.69% loss: 1.4640/1.4637\n",
      "epoch: 37, progress: 59.54% loss: 1.4637/1.4637\n",
      "epoch: 37, progress: 79.39% loss: 1.4625/1.4634\n",
      "epoch: 37, progress: 99.24% loss: 1.4632/1.4634\n",
      "validation: 37, progress: 19.85% loss: 1.4637/1.4637, acc: 0.9974\n",
      "validation: 37, progress: 39.69% loss: 1.4629/1.4633, acc: 0.9978\n",
      "validation: 37, progress: 59.54% loss: 1.4636/1.4634, acc: 0.9977\n",
      "validation: 37, progress: 79.39% loss: 1.4628/1.4633, acc: 0.9979\n",
      "validation: 37, progress: 99.24% loss: 1.4637/1.4633, acc: 0.9978\n",
      "epoch: 37, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 38\n",
      "epoch: 38, progress: 19.85% loss: 1.4637/1.4637\n",
      "epoch: 38, progress: 39.69% loss: 1.4631/1.4634\n",
      "epoch: 38, progress: 59.54% loss: 1.4630/1.4632\n",
      "epoch: 38, progress: 79.39% loss: 1.4638/1.4634\n",
      "epoch: 38, progress: 99.24% loss: 1.4633/1.4634\n",
      "validation: 38, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 38, progress: 39.69% loss: 1.4637/1.4635, acc: 0.9977\n",
      "validation: 38, progress: 59.54% loss: 1.4633/1.4634, acc: 0.9977\n",
      "validation: 38, progress: 79.39% loss: 1.4631/1.4633, acc: 0.9978\n",
      "validation: 38, progress: 99.24% loss: 1.4635/1.4634, acc: 0.9978\n",
      "epoch: 38, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39, progress: 19.85% loss: 1.4624/1.4624\n",
      "epoch: 39, progress: 39.69% loss: 1.4633/1.4628\n",
      "epoch: 39, progress: 59.54% loss: 1.4638/1.4632\n",
      "epoch: 39, progress: 79.39% loss: 1.4640/1.4634\n",
      "epoch: 39, progress: 99.24% loss: 1.4633/1.4633\n",
      "validation: 39, progress: 19.85% loss: 1.4637/1.4637, acc: 0.9974\n",
      "validation: 39, progress: 39.69% loss: 1.4634/1.4636, acc: 0.9976\n",
      "validation: 39, progress: 59.54% loss: 1.4633/1.4635, acc: 0.9977\n",
      "validation: 39, progress: 79.39% loss: 1.4631/1.4634, acc: 0.9978\n",
      "validation: 39, progress: 99.24% loss: 1.4631/1.4633, acc: 0.9978\n",
      "epoch: 39, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 40\n",
      "epoch: 40, progress: 19.85% loss: 1.4628/1.4628\n",
      "epoch: 40, progress: 39.69% loss: 1.4628/1.4628\n",
      "epoch: 40, progress: 59.54% loss: 1.4627/1.4628\n",
      "epoch: 40, progress: 79.39% loss: 1.4642/1.4631\n",
      "epoch: 40, progress: 99.24% loss: 1.4641/1.4633\n",
      "validation: 40, progress: 19.85% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 40, progress: 39.69% loss: 1.4630/1.4633, acc: 0.9979\n",
      "validation: 40, progress: 59.54% loss: 1.4640/1.4635, acc: 0.9976\n",
      "validation: 40, progress: 79.39% loss: 1.4627/1.4633, acc: 0.9979\n",
      "validation: 40, progress: 99.24% loss: 1.4637/1.4634, acc: 0.9978\n",
      "epoch: 40, train loss: 1.4633, validation accuracy: 0.9978\n",
      "epoch: 41\n",
      "epoch: 41, progress: 19.85% loss: 1.4634/1.4634\n",
      "epoch: 41, progress: 39.69% loss: 1.4637/1.4636\n",
      "epoch: 41, progress: 59.54% loss: 1.4633/1.4635\n",
      "epoch: 41, progress: 79.39% loss: 1.4636/1.4635\n",
      "epoch: 41, progress: 99.24% loss: 1.4630/1.4634\n",
      "validation: 41, progress: 19.85% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 41, progress: 39.69% loss: 1.4631/1.4633, acc: 0.9978\n",
      "validation: 41, progress: 59.54% loss: 1.4632/1.4633, acc: 0.9978\n",
      "validation: 41, progress: 79.39% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 41, progress: 99.24% loss: 1.4637/1.4634, acc: 0.9978\n",
      "epoch: 41, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 42\n",
      "epoch: 42, progress: 19.85% loss: 1.4620/1.4620\n",
      "epoch: 42, progress: 39.69% loss: 1.4631/1.4626\n",
      "epoch: 42, progress: 59.54% loss: 1.4637/1.4630\n",
      "epoch: 42, progress: 79.39% loss: 1.4641/1.4633\n",
      "epoch: 42, progress: 99.24% loss: 1.4639/1.4634\n",
      "validation: 42, progress: 19.85% loss: 1.4637/1.4637, acc: 0.9974\n",
      "validation: 42, progress: 39.69% loss: 1.4630/1.4633, acc: 0.9978\n",
      "validation: 42, progress: 59.54% loss: 1.4630/1.4632, acc: 0.9979\n",
      "validation: 42, progress: 79.39% loss: 1.4636/1.4633, acc: 0.9979\n",
      "validation: 42, progress: 99.24% loss: 1.4632/1.4633, acc: 0.9979\n",
      "epoch: 42, train loss: 1.4634, validation accuracy: 0.9979\n",
      "val_acc (0.9978530534351145) > best_acc (0.9978232347328244), updating\n",
      "epoch: 43\n",
      "epoch: 43, progress: 19.85% loss: 1.4640/1.4640\n",
      "epoch: 43, progress: 39.69% loss: 1.4631/1.4636\n",
      "epoch: 43, progress: 59.54% loss: 1.4636/1.4636\n",
      "epoch: 43, progress: 79.39% loss: 1.4633/1.4635\n",
      "epoch: 43, progress: 99.24% loss: 1.4629/1.4634\n",
      "validation: 43, progress: 19.85% loss: 1.4637/1.4637, acc: 0.9974\n",
      "validation: 43, progress: 39.69% loss: 1.4634/1.4635, acc: 0.9976\n",
      "validation: 43, progress: 59.54% loss: 1.4622/1.4631, acc: 0.9980\n",
      "validation: 43, progress: 79.39% loss: 1.4637/1.4632, acc: 0.9979\n",
      "validation: 43, progress: 99.24% loss: 1.4633/1.4632, acc: 0.9979\n",
      "epoch: 43, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 44\n",
      "epoch: 44, progress: 19.85% loss: 1.4638/1.4638\n",
      "epoch: 44, progress: 39.69% loss: 1.4631/1.4635\n",
      "epoch: 44, progress: 59.54% loss: 1.4630/1.4633\n",
      "epoch: 44, progress: 79.39% loss: 1.4632/1.4633\n",
      "epoch: 44, progress: 99.24% loss: 1.4637/1.4634\n",
      "validation: 44, progress: 19.85% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 44, progress: 39.69% loss: 1.4633/1.4632, acc: 0.9980\n",
      "validation: 44, progress: 59.54% loss: 1.4637/1.4634, acc: 0.9978\n",
      "validation: 44, progress: 79.39% loss: 1.4636/1.4634, acc: 0.9977\n",
      "validation: 44, progress: 99.24% loss: 1.4633/1.4634, acc: 0.9978\n",
      "epoch: 44, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 45\n",
      "epoch: 45, progress: 19.85% loss: 1.4631/1.4631\n",
      "epoch: 45, progress: 39.69% loss: 1.4629/1.4630\n",
      "epoch: 45, progress: 59.54% loss: 1.4645/1.4635\n",
      "epoch: 45, progress: 79.39% loss: 1.4626/1.4633\n",
      "epoch: 45, progress: 99.24% loss: 1.4636/1.4633\n",
      "validation: 45, progress: 19.85% loss: 1.4631/1.4631, acc: 0.9980\n",
      "validation: 45, progress: 39.69% loss: 1.4632/1.4632, acc: 0.9980\n",
      "validation: 45, progress: 59.54% loss: 1.4635/1.4633, acc: 0.9978\n",
      "validation: 45, progress: 79.39% loss: 1.4626/1.4631, acc: 0.9980\n",
      "validation: 45, progress: 99.24% loss: 1.4642/1.4634, acc: 0.9978\n",
      "epoch: 45, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 46\n",
      "epoch: 46, progress: 19.85% loss: 1.4626/1.4626\n",
      "epoch: 46, progress: 39.69% loss: 1.4634/1.4630\n",
      "epoch: 46, progress: 59.54% loss: 1.4640/1.4633\n",
      "epoch: 46, progress: 79.39% loss: 1.4634/1.4634\n",
      "epoch: 46, progress: 99.24% loss: 1.4634/1.4634\n",
      "validation: 46, progress: 19.85% loss: 1.4636/1.4636, acc: 0.9976\n",
      "validation: 46, progress: 39.69% loss: 1.4626/1.4631, acc: 0.9980\n",
      "validation: 46, progress: 59.54% loss: 1.4640/1.4634, acc: 0.9977\n",
      "validation: 46, progress: 79.39% loss: 1.4634/1.4634, acc: 0.9977\n",
      "validation: 46, progress: 99.24% loss: 1.4630/1.4633, acc: 0.9978\n",
      "epoch: 46, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 47\n",
      "epoch: 47, progress: 19.85% loss: 1.4635/1.4635\n",
      "epoch: 47, progress: 39.69% loss: 1.4636/1.4635\n",
      "epoch: 47, progress: 59.54% loss: 1.4639/1.4637\n",
      "epoch: 47, progress: 79.39% loss: 1.4629/1.4635\n",
      "epoch: 47, progress: 99.24% loss: 1.4625/1.4633\n",
      "validation: 47, progress: 19.85% loss: 1.4640/1.4640, acc: 0.9971\n",
      "validation: 47, progress: 39.69% loss: 1.4625/1.4633, acc: 0.9979\n",
      "validation: 47, progress: 59.54% loss: 1.4642/1.4636, acc: 0.9976\n",
      "validation: 47, progress: 79.39% loss: 1.4631/1.4634, acc: 0.9977\n",
      "validation: 47, progress: 99.24% loss: 1.4631/1.4634, acc: 0.9978\n",
      "epoch: 47, train loss: 1.4633, validation accuracy: 0.9978\n",
      "epoch: 48\n",
      "epoch: 48, progress: 19.85% loss: 1.4640/1.4640\n",
      "epoch: 48, progress: 39.69% loss: 1.4629/1.4635\n",
      "epoch: 48, progress: 59.54% loss: 1.4629/1.4633\n",
      "epoch: 48, progress: 79.39% loss: 1.4640/1.4635\n",
      "epoch: 48, progress: 99.24% loss: 1.4630/1.4634\n",
      "validation: 48, progress: 19.85% loss: 1.4642/1.4642, acc: 0.9970\n",
      "validation: 48, progress: 39.69% loss: 1.4631/1.4636, acc: 0.9975\n",
      "validation: 48, progress: 59.54% loss: 1.4632/1.4635, acc: 0.9976\n",
      "validation: 48, progress: 79.39% loss: 1.4631/1.4634, acc: 0.9977\n",
      "validation: 48, progress: 99.24% loss: 1.4633/1.4634, acc: 0.9978\n",
      "epoch: 48, train loss: 1.4634, validation accuracy: 0.9978\n",
      "epoch: 49\n",
      "epoch: 49, progress: 19.85% loss: 1.4637/1.4637\n",
      "epoch: 49, progress: 39.69% loss: 1.4631/1.4634\n",
      "epoch: 49, progress: 59.54% loss: 1.4637/1.4635\n",
      "epoch: 49, progress: 79.39% loss: 1.4640/1.4636\n",
      "epoch: 49, progress: 99.24% loss: 1.4623/1.4634\n",
      "validation: 49, progress: 19.85% loss: 1.4633/1.4633, acc: 0.9979\n",
      "validation: 49, progress: 39.69% loss: 1.4635/1.4634, acc: 0.9977\n",
      "validation: 49, progress: 59.54% loss: 1.4633/1.4634, acc: 0.9978\n",
      "validation: 49, progress: 79.39% loss: 1.4634/1.4634, acc: 0.9978\n",
      "validation: 49, progress: 99.24% loss: 1.4634/1.4634, acc: 0.9978\n",
      "epoch: 49, train loss: 1.4634, validation accuracy: 0.9978\n",
      "validation: 49, progress: 19.85% loss: 1.4634/1.4634, acc: 0.9977\n",
      "validation: 49, progress: 39.69% loss: 1.4625/1.4629, acc: 0.9982\n",
      "validation: 49, progress: 59.54% loss: 1.4639/1.4632, acc: 0.9979\n",
      "validation: 49, progress: 79.39% loss: 1.4637/1.4634, acc: 0.9978\n",
      "validation: 49, progress: 99.24% loss: 1.4634/1.4634, acc: 0.9978\n",
      "current: train loss: 1.4634, validation loss: 0.9978\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.00001)\n",
    "\n",
    "# n_epochs = 50\n",
    "\n",
    "def validation():\n",
    "    loss_all = 0.0\n",
    "    loss_cur = 0.0\n",
    "\n",
    "    n_batches = len(loader_val)\n",
    "    print_every = n_batches // 5\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, data in enumerate(loader_val):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = Variable(inputs.to(device)), Variable(targets.to(device))\n",
    "        outputs = net(inputs)\n",
    "        loss_size = loss(outputs, targets)\n",
    "        loss_all += float(loss_size.data)\n",
    "        loss_cur += float(loss_size.data)\n",
    "        \n",
    "        _, vpredicted = torch.max(outputs, 1)\n",
    "        for pi, predicted in enumerate(vpredicted):\n",
    "            expected = int(targets[pi])\n",
    "            if expected == predicted:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "                \n",
    "        if (i + 1 ) % print_every == 0:\n",
    "            avg_loss_all = loss_all / (i + 1)\n",
    "            avg_loss_cur = loss_cur / print_every\n",
    "            loss_cur = 0.0\n",
    "            acc = correct / total\n",
    "            print(\"validation: {}, progress: {:.02f}% loss: {:.04f}/{:.04f}, acc: {:.04f}\".format(\n",
    "                epoch, \n",
    "                (100 * (i+1)/n_batches),\n",
    "                avg_loss_cur,\n",
    "                avg_loss_all,\n",
    "                acc,\n",
    "            ))\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return correct / total\n",
    "        \n",
    "n_batches = len(loader_train)\n",
    "print_every = n_batches // 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss_all = 0.0\n",
    "    loss_cur = 0.0\n",
    "\n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    for i, data in enumerate(loader_train):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = Variable(inputs.to(device)), Variable(targets.to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss_size = loss(outputs, targets)\n",
    "        loss_size.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_all += float(loss_size.data)\n",
    "        loss_cur += float(loss_size.data)\n",
    "        \n",
    "        if (i + 1 ) % print_every == 0:\n",
    "            avg_loss_all = loss_all / (i + 1)\n",
    "            avg_loss_cur = loss_cur / print_every\n",
    "            loss_cur = 0.0\n",
    "            print(\"epoch: {}, progress: {:.02f}% loss: {:.04f}/{:.04f}\".format(\n",
    "                epoch, \n",
    "                (100 * (i+1)/n_batches),\n",
    "                avg_loss_cur,\n",
    "                avg_loss_all,\n",
    "            ))\n",
    " \n",
    "    train_loss = loss_all / n_batches\n",
    "    val_acc = validation()\n",
    "    print(\"epoch: {}, train loss: {:.04f}, validation accuracy: {:.04f}\".format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                val_acc,\n",
    "            ))\n",
    "    if val_acc > best_acc:\n",
    "        print(\"val_acc ({}) > best_acc ({}), updating\".format(val_acc, best_acc))\n",
    "        net.save(\"best\")\n",
    "        best_acc = val_acc\n",
    "\n",
    "net.load(\"best\")\n",
    "last_val = validation()\n",
    "print(\"current: train loss: {:.04f}, validation loss: {:.04f}\".format(\n",
    "                train_loss,\n",
    "                last_val,\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save progress: 19.63%\n",
      "save progress: 39.27%\n",
      "save progress: 58.90%\n",
      "save progress: 78.54%\n",
      "save progress: 98.17%\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "with open(file_result, \"w\") as f:\n",
    "    il = 1\n",
    "    f.write('ImageId,Label\\n')\n",
    "    n_batches = len(loader_test)\n",
    "    print_every = n_batches // 5\n",
    "    for i, data in enumerate(loader_test):\n",
    "        inputs, _ = data\n",
    "        inputs = Variable(inputs.to(device))\n",
    "        outputs = net(inputs)\n",
    "        _, vpredicted = torch.max(outputs, 1)\n",
    "        for pi, predicted in enumerate(vpredicted):\n",
    "            f.write(\"{},{}\\n\".format(il, predicted))\n",
    "            il += 1\n",
    "\n",
    "        if (i + 1 ) % print_every == 0:\n",
    "            print(\"save progress: {:.02f}%\".format(\n",
    "                (100 * (i+1)/n_batches),\n",
    "            ))\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
